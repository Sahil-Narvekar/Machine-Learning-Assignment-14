{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. What is the concept of supervised learning? What is the significance of the name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Supervised learning, also known as supervised machine learning, is a subcategory of machine learning and \n",
    "artificial intelligence. It is defined by its use of labeled datasets to train algorithms that to classify\n",
    "data or predict outcomes accurately.\n",
    "It is called supervised learning because the process of an algorithm learning from the training dataset \n",
    "can be thought of as a teacher supervising the learning process. We know the correct answers, the \n",
    "algorithm iteratively makes predictions on the training data and is corrected by the teacher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2. In the hospital sector, offer an example of supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Detection of cancer tumor in human body is example of supervised learning since depending on previous \n",
    "recorded datasets the algorithm is taught and new data is classified as yes or no.Since the labeled\n",
    "dataset was given to train the algorithm it is supervised learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Give three supervised learning examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Common supervised learning algorithms include: Linear regression; Naïve Bayes, Nearest Neighbours,\n",
    "Decision Trees, Support Vector Machines and Neural Networks.\n",
    "Its applications are \n",
    "Image classification is a popular problem in the computer vision field.\n",
    "\n",
    "Predicting house prices.\n",
    "\n",
    "Predicting whether it is going to snow or not tomorrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4. In supervised learning, what are classification and regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classification is a supervised learning concept which basically categorizes a set of data into classes. \n",
    "The most common classification problems are – speech recognition, face detection, handwriting recognition,\n",
    "document classification, etc.\n",
    "\n",
    "Regression analysis consists of a set of machine learning methods that allow us to predict a continuous\n",
    "outcome variable (y) based on the value of one or multiple predictor variables (x). Briefly, the goal of\n",
    "regression model is to build a mathematical equation that defines y as a function of the x variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Give some popular classification algorithms as examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic regression is a machine learning algorithm for classification. In this algorithm, the \n",
    "probabilities describing the possible outcomes of a single trial are modelled using a logistic function.\n",
    "Example:Spam detection and Tumor detection\n",
    "\n",
    "Naive Bayes algorithm based on Bayes’ theorem with the assumption of independence between every pair of \n",
    "features. Naive Bayes classifiers work well in many real-world situations such as document classification\n",
    "and spam filtering.\n",
    "\n",
    "Neighbours based classification is a type of lazy learning as it does not attempt to construct a general \n",
    "internal model, but simply stores instances of the training data. Classification is computed from a \n",
    "simple majority vote of the k nearest neighbours of each point.\n",
    "Used in detecting outliers(Credit Card fraud detection)\n",
    "KNN can search for semantically similar documents. Each document is considered as a vector. If documents \n",
    "are close to each other, that means the documents contain identical topics.\n",
    "\n",
    "Decision Tree\n",
    "Given a data of attributes together with its classes, a decision tree produces a sequence\n",
    "of rules that can be used to classify the data.\n",
    "Lenders  use decision trees to predict the probability of a customer defaulting on a loan, by \n",
    "applying predictive model generation using the client’s past data.\n",
    "Historical data on sales can be used in decision trees that may lead to making radical changes in\n",
    "the strategy of a business to help aid expansion and growth.\n",
    "\n",
    " Random forest classifier is a meta-estimator that fits a number of decision trees on various sub-samples \n",
    "of datasets and uses average to improve the predictive accuracy of the model and controls over-fitting.\n",
    "The sub-sample size is always the same as the original input sample size but the samples are drawn with\n",
    "replacement.\n",
    "Price Optimization,Search Ranking,Stock Market Sentiment Analysis,Bitcoin Price Detection\n",
    "\n",
    "Support vector machine is a representation of the training data as points in space separated into\n",
    "categories by a clear gap that is as wide as possible. New examples are then mapped into that same space \n",
    "and predicted to belong to a category based on which side of the gap they fall.\n",
    "Protein Fold and Remote Homology Detection:The kernel functions help to find the similarity between \n",
    "different protein sequences.\n",
    "Images of certain textures and use that data to classify whether the surface is smooth or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Briefly describe the SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "“Support Vector Machine” (SVM) is a supervised machine learning algorithm which can be used for both\n",
    "classification or regression challenges. However,  it is mostly used in classification problems. In the\n",
    "SVM algorithm, we plot each data item as a point in n-dimensional space (where n is number of features you \n",
    "have) with the value of each feature being the value of a particular coordinate. Then, we perform \n",
    "classification by finding the hyper-plane that differentiates the two classes very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7. In SVM, what is the cost of misclassification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The cost parameter decides how much an SVM should be allowed to “bend” with the data. For a low cost, you\n",
    "aim for a smooth decision surface and for a higher cost, you aim to classify more points correctly. It is \n",
    "also simply referred to as the cost of misclassification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8. In the SVM model, define Support Vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Support vectors are data points that are closer to the hyperplane and influence the position and \n",
    "orientation of the hyperplane. Using these support vectors, we maximize the margin of the classifier. \n",
    "Deleting the support vectors will change the position of the hyperplane. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9. In the SVM model, define the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM algorithms use a set of mathematical functions that are defined as the kernel. The function of kernel \n",
    "is to take data as input and transform it into the required form. For example linear, nonlinear,\n",
    "polynomial, radial basis function (RBF), and sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10. What are the factors that influence SVM's effectiveness?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The SVM effectiveness depends upon how you choose the depends on selection of kernel,kernel parameters,soft\n",
    "margin parameter c in such a waythat it maximises your efficiency, reduces error and overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11. What are the benefits of using the SVM model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM works relatively well when there is a clear margin of separation between classes.\n",
    "SVM is more effective in high dimensional spaces.\n",
    "SVM is effective in cases where the number of dimensions is greater than the number of samples.\n",
    "SVM is relatively memory efficient.\n",
    "SVM’s are very good when we have no idea on the data.\n",
    "Works well with even unstructured and semi structured data like text, Images and trees.\n",
    "The kernel trick is real strength of SVM. With an appropriate kernel function, we can solve any \n",
    "complex problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "12. What are the drawbacks of using the SVM model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Choosing a “good” kernel function is not easy.\n",
    "Long training time for large datasets.\n",
    "Since the final model is not so easy to see, we can not do small calibrations to the model hence its tough\n",
    "to incorporate our business logic.\n",
    "The SVM hyper parameters are Cost -C and gamma. It is not that easy to fine-tune these hyper-parameters.\n",
    "It is hard to visualize their impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13. Notes should be written on\n",
    "\n",
    "1. The kNN algorithm has a validation flaw.\n",
    "\n",
    "2. In the kNN algorithm, the k value is chosen.\n",
    "\n",
    "3. A decision tree with inductive bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In cross-validation, instead of splitting the data into two parts, we split it into 3. Training data, \n",
    "cross-validation data, and test data. Here, we use training data for finding nearest neighbors, we use \n",
    "cross-validation data to find the best value of “K” and finally we test our model on totally unseen test\n",
    "data. This test data is equivalent to the future unseen data points.\n",
    "\n",
    "In KNN, finding the value of k is not easy. A small value of k means that noise will have a higher \n",
    "influence on the result and a large value make it computationally expensive. Data scientists usually \n",
    "choose as an odd number if the number of classes is 2 and another simple approach to select k is set \n",
    "k=sqrt(n).\n",
    "\n",
    "Shorter trees are preferred over longer ones.\n",
    "Trees that place high information gain attributes close to the root are preferred over those that do not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "14. What are some of the benefits of the kNN algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quick calculation time.\n",
    "Simple algorithm – to interpret.\n",
    "Versatile – useful for regression and classification.\n",
    "High accuracy – you do not need to compare with better-supervised learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "15. What are some of the kNN algorithm.s drawbacks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy depends on the quality of the data.\n",
    "With large data, the prediction stage might be slow.\n",
    "Sensitive to the scale of the data and irrelevant features.\n",
    "Require high memory – need to store all of the training data.\n",
    "Given that it stores all of the training, it can be computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "16. Explain the decision tree algorithm in a few words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The decision tree algorithm tries to solve the problem, by using tree representation. Each internal node \n",
    "of the tree corresponds to an attribute, and each leaf node corresponds to a class label.\n",
    "step1:Place the best attribute of the dataset at the root of the tree.\n",
    "step2:Split the training set into subsets. Subsets should be made in such a way that each subset contains \n",
    "data with the same value for an attribute.\n",
    "Repeat step 1 and step 2 on each subset until you find leaf nodes in all the branches of the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "17. What is the difference between a node and a leaf in a decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A decision tree is a flowchart-like structure in which each internal node represents a \"test\" on an \n",
    "attribute (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the \n",
    "test, and each leaf node represents a class label (decision taken after computing all attributes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "18. What is a decision tree's entropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Entropy. A decision tree is built top-down from a root node and involves partitioning the data into subsets\n",
    "that contain instances with similar values (homogenous). ID3 algorithm uses entropy to calculate the \n",
    "homogeneity of a sample.\n",
    "If the sample is completely homogeneous the entropy is zero and if the sample is an equally divided it \n",
    "has entropy of one.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "19. In a decision tree, define knowledge gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Information gain is the reduction in entropy or surprise by transforming a dataset and is often used in \n",
    "training decision trees. Information gain is calculated by comparing the entropy of the dataset before\n",
    "and after a transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20. Choose three advantages of the decision tree approach and write them down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Understanding the results is easier than other models. \n",
    "It is non-parametric.\n",
    "They are capable of working with missing values.\n",
    "Extreme individual values (such as outliers) don't have much effect on the decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "21. Make a list of three flaws in the decision tree process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Decision trees cannot be used well with continuous numerical variables. \n",
    "A small change in the data tendsto cause a big difference in the tree structure, which causes instability.\n",
    "Calculations involved can also become complex compared to other algorithms, and it takes a longer time to \n",
    "train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "22. Briefly describe the random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random forest is a supervised learning algorithm. The \"forest\" it builds, is an ensemble of decision trees,\n",
    "usually trained with the “bagging” method. The general idea of the bagging method is that a combination of \n",
    "learning models increases the overall result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
